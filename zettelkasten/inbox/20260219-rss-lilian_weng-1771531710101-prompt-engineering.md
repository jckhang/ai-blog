---
id: 20260219-rss-lilian_weng-XXX-prompt-engineering
title: Prompt Engineering
created: 2026-02-19
tags: ["rss", "engineering", "auto-import"]
source: "Lilian Weng's Blog"
source_url: "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/"
source_type: "article"
content_length: 723
quality_score: 0.70
---

# Prompt Engineering

## 原文概览

- **来源**: Lilian Weng's Blog
- **发布时间**: Wed, 15 Mar 2023 00:00:00 +0000
- **原文链接**: https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/
- **抓取时间**: 2026-02-19T20:08:30.101Z

## 核心内容

**Prompt Engineering**, also known as **In-Context Prompting**, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes *without* updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.

This post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my [previous post](https://lilianweng.github.io/posts/2021-01-02-controllable-text-generation/) on controllable text generation.

## 关键观点

<!-- TODO: 人工或LLM提取3-5个关键观点 -->

## 相关链接

- [[TODO-添加相关ZK卡片]]

---
*RSS 自动抓取 - 抓取时间: 2026-02-19T20:08:30.101Z*