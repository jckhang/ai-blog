---
id: 20260220-rss-huggingface_blog-001-community-evals-because-we-re-done-trusting-black
title: Community Evals: Because we're done trusting black-box leaderboards over the community
created: 2026-02-21
tags: ["rss","ai_research","auto-import","permanent"]
source: "Hugging Face Blog"
source_url: "https://huggingface.co/blog/community-evals"
source_type: "article"
content_length: 25288
quality_score: 0.95
---

# Community Evals: Because we're done trusting black-box leaderboards over the community

## æ¥æºä¿¡æ¯

- **æ¥æº**: Hugging Face Blog
- **å‘å¸ƒæ—¶é—´**: è§åŸæ–‡
- **åŸæ–‡é“¾æ¥**: https://huggingface.co/blog/community-evals
- **é‡‡é›†æ—¶é—´**: 2026-02-21

## æ ¸å¿ƒå†…å®¹

const guestTheme = document.cookie.match(/theme=(\w+)/)?.[1]; document.documentElement.classList.toggle('dark', guestTheme === 'dark' || ( (!guestTheme || guestTheme === 'system') && window.matchMedia('(prefers-color-scheme: dark)').matches)); Community Evals: Because we&#39;re done trusting black-box leaderboards over the community ((window.plausible = window.plausible || function () { (plausible.q = plausible.q || []).push(arguments); }), (plausible.init = plausible.init || function (i) { plausible.o = i || {}; })); plausible.init({ customProperties: { loggedIn: "false", }, endpoint: "/api/event", }); window.hubConfig = {"features":{"signupDisabled":false},"sshGitUrl":"git@hf.co","moonHttpUrl":"https:\/\/huggingface.co","captchaApiKey":"bd5f2066-93dc-4bdd-a64b-a24646ca3859","datasetViewerPublicUrl":"https:\/\/datasets-server.huggingface.co","stripePublicKey":"pk_live_x2tdjFXBCvXo2FFmMybezpeM00J6gPCAAc","environment":"production","userAgent":"HuggingFace (production)","spacesIframeDomain":"hf.space","spacesApiUrl":"https:\/\/api.hf.space","docSearchKey":"ece5e02e57300e17d152c08056145326e90c4bff3dd07d7d1ae40cf1c8d39cb6","logoDev":{"apiUrl":"https:\/\/img.logo.dev\/","apiKey":"pk_UHS2HZOeRnaSOdDp7jbd5w"}}; window.requestId = "Root=1-6998536b-00245c9977e9bd1a7991e8cc"; window.featureFlags = {"buckets":false}; Hugging Face Models Datasets Spaces Community Docs Enterprise Pricing Log In Sign Up Back to Articles Community Evals: Because we're done trusting black-box leaderboards over the community Published February 4, 2026 Update on GitHub Upvote 72 +66 ben burtenshaw burtenshaw Follow Nathan Habib SaylorTwift Follow Bertrand Chevrier kramp Follow merve merve Follow Daniel van Strien davanstrien Follow Niels Rogge nielsr Follow Julien Chaumond julien-c Follow Evaluation is broken What We&#39;re Shipping Why This Matters Get Started TL;DR: Benchmark datasets on Hugging Face can now host leaderboards. Models store their own eval scores. Everything links together. The community can submit results via PR. Verified badges prove that the results can be reproduced. Evaluation is broken Let's be real about where we are with evals in 2026. MMLU is saturated above 91%. GSM8K hit 94%+. HumanEval is conquered. Yet some models that ace benchmarks still can't reliably browse the web, write production code, or handle multi-step tasks without hallucinating, based on usage reports. There is a clear gap between benchmark scores and real-world performance. Furthermore, there is another gap within reported benchmark scores. Multiple sources report different results. From Model Cards, to papers, to evaluation platforms, there is no alignment in reported scores. The result is that the community lacks a single source of truth. What We're Shipping Decentralized and transparent evaluation reporting. We are going to take evaluations on the Hugging Face Hub in a new direction by decentralizing reporting and allowing the entire community to openly report scores for benchmarks. At first, we will start with a shortlist of 4 benchmarks and over time weâ€™ll expand to the most relevant benchmarks. For Benchmarks: Dataset repos can now register as benchmarks ( MMLU-Pro , GPQA , HLE are already live). They automatically aggregate reported results from across the Hub and display leaderboards in the dataset card. The benchmark defines the eval spec via eval.yaml , based on the Inspect AI format, so anyone can reproduce it. The reported results need to align with the task definition. For Models: Eval scores live in .eval_results/*.yaml in the model repo. They appear on the model card and are fed into benchmark datasets. Both the model authorâ€™s results and open pull requests for results will be aggregated. Model authors will be able to close score PR and hide results. For the Community: Any user can submit evaluation results for any model via a PR. Results get shown as "community", without waiting for model authors to merge or close. The community can link to sources like a paper, Model Card, third-party evaluation platform, or inspect eval logs. The community can discuss scores like any PR. Since the Hub is Git based, there is a history of when evals were added, when changes were made, etc. The sources look like below. To learn more about evaluation results, check out the docs . Model scores in the Hub Why This Matters Decentralizing evaluation will expose scores that already exist across the community in sources like model cards and papers. By exposing these scores, the community can build on top of them to aggregate, track, and understand scores across the field. Also, all scores will be exposed via Hub APIs, making it easy to aggregate and build curated leaderboards, dashboards, etc. Community evals do not replace benchmarks so leaderboards and closed evals with published results are still crucial. However, we believe it's important to contribute to the field with open eval results based on reproducible eval specs. This won't solve benchmark saturation or close the benchmark-reality gap. Nor will it stop training on test sets. But it makes the game visible by exposing what is evaluated, how, when, and by whom. Mostly, we hope to make the Hub an active place to build and share reproducible benchmarks. Particularly focusing on new tasks and domains that challenge SOTA models more. Get Started Read the docs: To learn more about evaluation results, check out the docs . Add eval results: Publish the evals you conducted as YAML files in .eval_results/ on any model repo. Check out the scores on the benchmark dataset . Register a new benchmark: Add eval.yaml to your dataset repo and contact us to be included in the shortlist. The feature is in beta. We're building in the open. Feedback welcome. More Articles from our Blog swift hub open-source Introducing swift-huggingface: The Complete Swift Client for Hugging Face 43 December 5, 2025 open-source LLM community ğŸ‡µğŸ‡­ FilBench - Can LLMs Understand and Generate Filipino? +5 23 August 12, 2025 Community Great initiative, aggregating multiple signals is the way to go! \n&quot;,&quot;updatedAt&quot;:&quot;2026-02-06T15:01:54.452Z&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;61b8e2ba285851687028d395&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/61b8e2ba285851687028d395/Rq3xWG7mJ3aCRoBsq340h.jpeg&quot;,&quot;fullname&quot;:&quot;Maxime Labonne&quot;,&quot;name&quot;:&quot;mlabonne&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:true,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:7139,&quot;isUserFollowing&quot;:false}},&quot;numEdits&quot;:0,&quot;identifiedLanguage&quot;:{&quot;language&quot;:&quot;en&quot;,&quot;probability&quot;:0.8993434309959412},&quot;editors&quot;:[&quot;mlabonne&quot;],&quot;editorAvatarUrls&quot;:[&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/61b8e2ba285851687028d395/Rq3xWG7mJ3aCRoBsq340h.jpeg&quot;],&quot;reactions&quot;:[{&quot;reaction&quot;:&quot;â¤ï¸&quot;,&quot;users&quot;:[&quot;SaylorTwift&quot;,&quot;kramp&quot;,&quot;Neilblaze&quot;],&quot;count&quot;:3}],&quot;isReport&quot;:false}},{&quot;id&quot;:&quot;6986c939e1b677c5df5c3afb&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;692d667ac31ca24423a625a5&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/692d667ac31ca24423a625a5/8Ms5uofPtBYD6Oj4rBQD_.jpeg&quot;,&quot;fullname&quot;:&quot;NJX-njx&quot;,&quot;name&quot;:&quot;NJX-njx&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:8,&quot;isUserFollowing&quot;:false},&quot;createdAt&quot;:&quot;2026-02-07T05:10:17.000Z&quot;,&quot;type&quot;:&quot;comment&quot;,&quot;data&quot;:{&quot;edited&quot;:false,&quot;hidden&quot;:false,&quot;latest&quot;:{&quot;raw&quot;:&quot;Although such a measure has not solved the problems encountered in the current evaluation, at least it is indeed a very good measure in terms of decentralization and mobilizing the power of the community for co-construction.&quot;,&quot;html&quot;:&quot; Although such a measure has not solved the problems encountered in the current evaluation, at least it is indeed a very good measure in terms of decentralization and mobilizing the power of the community for co-construction. \n&quot;,&quot;updatedAt&quot;:&quot;2026-02-07T05:10:17.062Z&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;692d667ac31ca24423a625a5&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/692d667ac31ca24423a625a5/8Ms5uofPtBYD6Oj4rBQD_.jpeg&quot;,&quot;fullname&quot;:&quot;NJX-njx&quot;,&quot;name&quot;:&quot;NJX-njx&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:8,&quot;isUserFollowing&quot;:false}},&quot;numEdits&quot;:0,&quot;identifiedLanguage&quot;:{&quot;language&quot;:&quot;en&quot;,&quot;probability&quot;:0.9713615775108337},&quot;editors&quot;:[&quot;NJX-njx&quot;],&quot;editorAvatarUrls&quot;:[&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/692d667ac31ca24423a625a5/8Ms5uofPtBYD6Oj4rBQD_.jpeg&quot;],&quot;reactions&quot;:[],&quot;isReport&quot;:false}},{&quot;id&quot;:&quot;69880808260cce8b14247341&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;63ec2270ca08a72ba9cf9bc0&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/63ec2270ca08a72ba9cf9bc0/zQrAf4ODgWWxLDRuD0pAh.png&quot;,&quot;fullname&quot;:&quot;Naufal Suryanto&quot;,&quot;name&quot;:&quot;naufalso&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:true,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:11,&quot;isUserFollowing&quot;:false},&quot;createdAt&quot;:&quot;2026-02-08T03:50:32.000Z&quot;,&quot;type&quot;:&quot;comment&quot;,&quot;data&quot;:{&quot;edited&quot;:true,&quot;hidden&quot;:false,&quot;latest&quot;:{&quot;raw&quot;:&quot;Will there be the integration with existing huggingface [lighteval](https://github.com/huggingface/lighteval)?&quot;,&quot;html&quot;:&quot; Will there be the integration with existing huggingface lighteval ? \n&quot;,&quot;updatedAt&quot;:&quot;2026-02-08T03:51:24.938Z&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;63ec2270ca08a72ba9cf9bc0&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/63ec2270ca08a72ba9cf9bc0/zQrAf4ODgWWxLDRuD0pAh.png&quot;,&quot;fullname&quot;:&quot;Naufal Suryanto&quot;,&quot;name&quot;:&quot;naufalso&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:true,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:11,&quot;isUserFollowing&quot;:false}},&quot;numEdits&quot;:1,&quot;identifiedLanguage&quot;:{&quot;language&quot;:&quot;en&quot;,&quot;probability&quot;:0.5559505820274353},&quot;editors&quot;:[&quot;naufalso&quot;],&quot;editorAvatarUrls&quot;:[&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/63ec2270ca08a72ba9cf9bc0/zQrAf4ODgWWxLDRuD0pAh.png&quot;],&quot;reactions&quot;:[],&quot;isReport&quot;:false}},{&quot;id&quot;:&quot;6989dfe0573fbffd10a8fbd6&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;63e0eea7af523c37e5a77966&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1678663263366-63e0eea7af523c37e5a77966.jpeg&quot;,&quot;fullname&quot;:&quot;Nathan Habib&quot;,&quot;name&quot;:&quot;SaylorTwift&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:true,&quot;isHf&quot;:true,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:317,&quot;isUserFollowing&quot;:false},&quot;createdAt&quot;:&quot;2026-02-09T13:23:44.000Z&quot;,&quot;type&quot;:&quot;comment&quot;,&quot;data&quot;:{&quot;edited&quot;:false,&quot;hidden&quot;:false,&quot;latest&quot;:{&quot;raw&quot;:&quot;hi @naufalso ! Lighteval now suport inspect-ai as a backend, so everything supported by inspect is integrrated in lighteval ğŸ”¥ &quot;,&quot;html&quot;:&quot; hi \n\n @ naufalso \n\t ! Lighteval now suport inspect-ai as a backend, so everything supported by inspect is integrrated in lighteval ğŸ”¥ \n&quot;,&quot;updatedAt&quot;:&quot;2026-02-09T13:23:44.361Z&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;63e0eea7af523c37e5a77966&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1678663263366-63e0eea7af523c37e5a77966.jpeg&quot;,&quot;fullname&quot;:&quot;Nathan Habib&quot;,&quot;name&quot;:&quot;SaylorTwift&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:true,&quot;isHf&quot;:true,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:317,&quot;isUserFollowing&quot;:false}},&quot;numEdits&quot;:0,&quot;identifiedLanguage&quot;:{&quot;language&quot;:&quot;en&quot;,&quot;probability&quot;:0.7757905721664429},&quot;editors&quot;:[&quot;SaylorTwift&quot;],&quot;editorAvatarUrls&quot;:[&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1678663263366-63e0eea7af523c37e5a77966.jpeg&quot;],&quot;reactions&quot;:[{&quot;reaction&quot;:&quot;ğŸ‘&quot;,&quot;users&quot;:[&quot;naufalso&quot;],&quot;count&quot;:1}],&quot;isReport&quot;:false}},{&quot;id&quot;:&quot;698a04bae23462f322613301&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;683b6716b08ed58ff836343f&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/F3BvTROY7ooqDcsV6_igv.jpeg&quot;,&quot;fullname&quot;:&quot;Franklin Heng&quot;,&quot;name&quot;:&quot;hengloose&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:true,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;isUserFollowing&quot;:false},&quot;createdAt&quot;:&quot;2026-02-09T16:00:58.000Z&quot;,&quot;type&quot;:&quot;comment&quot;,&quot;data&quot;:{&quot;edited&quot;:false,&quot;hidden&quot;:false,&quot;latest&quot;:{&quot;raw&quot;:&quot;Amazing&quot;,&quot;html&quot;:&quot; Amazing \n&quot;,&quot;updatedAt&quot;:&quot;2026-02-09T16:00:58.996Z&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;683b6716b08ed58ff836343f&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/F3BvTROY7ooqDcsV6_igv.jpeg&quot;,&quot;fullname&quot;:&quot;Franklin Heng&quot;,&quot;name&quot;:&quot;hengloose&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:true,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;isUserFollowing&quot;:false}},&quot;numEdits&quot;:0,&quot;identifiedLanguage&quot;:{&quot;language&quot;:&quot;en&quot;,&quot;probability&quot;:0.28397423028945923},&quot;editors&quot;:[&quot;hengloose&quot;],&quot;editorAvatarUrls&quot;:[&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/F3BvTROY7ooqDcsV6_igv.jpeg&quot;],&quot;reactions&quot;:[],&quot;isReport&quot;:false}},{&quot;id&quot;:&quot;698a283c3add708a82c1f903&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;6657f6f91cdbe4e9b7c827f9&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/6657f6f91cdbe4e9b7c827f9/7UK9Gev5sikbBp-kC0RCg.png&quot;,&quot;fullname&quot;:&quot;Matthew Frank&quot;,&quot;name&quot;:&quot;MatthewFrank&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;isUserFollowing&quot;:false},&quot;createdAt&quot;:&quot;2026-02-09T18:32:28.000Z&quot;,&quot;type&quot;:&quot;comment&quot;,&quot;data&quot;:{&quot;edited&quot;:false,&quot;hidden&quot;:false,&quot;latest&quot;:{&quot;raw&quot;:&quot;This is such an important initiative for transparency in model evaluation! Building trustworthy evaluation infrastructure requires careful architectural design. For anyone building evaluation systems or ML infrastructure, clear documentation is critical. I've been using InfraSketch (https://www.infrasketch.net/) to document our evaluation pipelinesâ€”you describe the system architecture in plain English and get visual diagrams that you can iterate on conversationally. Makes it much easier to communicate how evaluation systems work and maintain documentation as they evolve.&quot;,&quot;html&quot;:&quot; This is such an important initiative for transparency in model evaluation! Building trustworthy evaluation infrastructure requires careful architectural design. For anyone building evaluation systems or ML infrastructure, clear documentation is critical. I've been using InfraSketch ( https://www.infrasketch.net/ ) to document our evaluation pipelinesâ€”you describe the system architecture in plain English and get visual diagrams that you can iterate on conversationally. Makes it much easier to communicate how evaluation systems work and maintain documentation as they evolve. \n&quot;,&quot;updatedAt&quot;:&quot;2026-02-09T18:32:28.845Z&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;6657f6f91cdbe4e9b7c827f9&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/6657f6f91cdbe4e9b7c827f9/7UK9Gev5sikbBp-kC0RCg.png&quot;,&quot;fullname&quot;:&quot;Matthew Frank&quot;,&quot;name&quot;:&quot;MatthewFrank&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;isUserFollowing&quot;:false}},&quot;numEdits&quot;:0,&quot;identifiedLanguage&quot;:{&quot;language&quot;:&quot;en&quot;,&quot;probability&quot;:0.8788459300994873},&quot;editors&quot;:[&quot;MatthewFrank&quot;],&quot;editorAvatarUrls&quot;:[&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/6657f6f91cdbe4e9b7c827f9/7UK9Gev5sikbBp-kC0RCg.png&quot;],&quot;reactions&quot;:[],&quot;isReport&quot;:false}},{&quot;id&quot;:&quot;698cc3459017bb9609f24fc4&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;648b67b2355113a5fba0ff31&quot;,&quot;avatarUrl&quot;:&quot;/avatars/8ea58a2e3f261d20b33c033992bc7f52.svg&quot;,&quot;fullname&quot;:&quot;Harsha Kokel&quot;,&quot;name&quot;:&quot;harshakokel&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;isUserFollowing&quot;:false},&quot;createdAt&quot;:&quot;2026-02-11T17:58:29.000Z&quot;,&quot;type&quot;:&quot;comment&quot;,&quot;data&quot;:{&quot;edited&quot;:true,&quot;hidden&quot;:false,&quot;latest&quot;:{&quot;raw&quot;:&quot;This is a very important and timely initiative. Itâ€™s easy to get lost in the sea of leaderboards, each with its own format and reporting style. The Inspect AI log format brings muchâ€‘needed standardization, and having Hugging Face host evaluation logs is a real game changer. One reason many valuable benchmarks fade away is that original contributors often lack the resources to continuously maintain leaderboards. The Community Evals initiative has tremendous potential to address this gap, and I truly appreciate the effort behind it. \n\nWeâ€™re hoping to include our planning benchmark, [ACPBench](https://ibm.github.io/ACPBench/index.html), as part of this ecosystemâ€”it's fully compatible with Inspect AI, the [evaluation scripts](https://github.com/IBM/ACPBench/blob/main/GettingStarted.md) are available on our GitHub.\n\n### References\n\n* ACPBench: Reasoning About Action, Change, and Planning, *Harsha Kokel, Michael Katz, Kavitha Srinivas, Shirin Sohrabi*, [AAAI 2025](https://ojs.aaai.org/index.php/AAAI/article/view/34857)\n* ACPBench Hard: Unrestrained Reasoning about Action, Change, and Planning, *Harsha Kokel, Michael Katz, Kavitha Srinivas, Shirin Sohrabi*, [ICLR 2026](https://openreview.net/forum?id=WIXohR7mEo)&quot;,&quot;html&quot;:&quot; This is a very important and timely initiative. Itâ€™s easy to get lost in the sea of leaderboards, each with its own format and reporting style. The Inspect AI log format brings muchâ€‘needed standardization, and having Hugging Face host evaluation logs is a real game changer. One reason many valuable benchmarks fade away is that original contributors often lack the resources to continuously maintain leaderboards. The Community Evals initiative has tremendous potential to address this gap, and I truly appreciate the effort behind it. \n Weâ€™re hoping to include our planning benchmark, ACPBench , as part of this ecosystemâ€”it's fully compatible with Inspect AI, the evaluation scripts are available on our GitHub. \n \n\t \n\t\t \n\t \n\t \n\t\tReferences\n\t \n \n \n ACPBench: Reasoning About Action, Change, and Planning, Harsha Kokel, Michael Katz, Kavitha Srinivas, Shirin Sohrabi , AAAI 2025 \n ACPBench Hard: Unrestrained Reasoning about Action, Change, and Planning, Harsha Kokel, Michael Katz, Kavitha Srinivas, Shirin Sohrabi , ICLR 2026 \n \n&quot;,&quot;updatedAt&quot;:&quot;2026-02-11T18:05:46.295Z&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;648b67b2355113a5fba0ff31&quot;,&quot;avatarUrl&quot;:&quot;/avatars/8ea58a2e3f261d20b33c033992bc7f52.svg&quot;,&quot;fullname&quot;:&quot;Harsha Kokel&quot;,&quot;name&quot;:&quot;harshakokel&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;isUserFollowing&quot;:false}},&quot;numEdits&quot;:2,&quot;identifiedLanguage&quot;:{&quot;language&quot;:&quot;en&quot;,&quot;probability&quot;:0.9256938695907593},&quot;editors&quot;:[&quot;harshakokel&quot;],&quot;editorAvatarUrls&quot;:[&quot;/avatars/8ea58a2e3f261d20b33c033992bc7f52.svg&quot;],&quot;reactions&quot;:[{&quot;reaction&quot;:&quot;â•&quot;,&quot;users&quot;:[&quot;ctpelok&quot;],&quot;count&quot;:1}],&quot;isReport&quot;:false}}],&quot;status&quot;:&quot;open&quot;,&quot;isReport&quot;:false,&quot;pinned&quot;:false,&quot;locked&quot;:false,&quot;collection&quot;:&quot;community_blogs&quot;},&quot;contextAuthors&quot;:[&quot;burtenshaw&quot;,&quot;SaylorTwift&quot;,&quot;kramp&quot;,&quot;merve&quot;,&quot;davanstrien&quot;,&quot;nielsr&quot;,&quot;julien-c&quot;],&quot;primaryEmailConfirmed&quot;:false,&quot;discussionRole&quot;:0,&quot;acceptLanguages&quot;:[&quot;en&quot;],&quot;withThread&quot;:true,&quot;cardDisplay&quot;:false,&quot;repoDiscussionsLocked&quot;:false}"> deleted 14 days ago This comment has been hidden mlabonne 14 days ago Great initiative, aggregating multiple signals is the way to go! â¤ï¸ 3 3 + Reply NJX-njx 13 days ago Although such a measure has not solved the problems encountered in the current evaluation, at least it is indeed a very good measure in terms of decentralization and mobilizing the power of the community for co-construction. Reply naufalso 12 days ago â€¢ edited 12 days ago Will there be the integration with existing huggingface lighteval ? Reply SaylorTwift Article author 11 days ago hi @ naufalso ! Lighteval now suport inspect-ai as a backend, so everything supported by inspect is integrrated in lighteval ğŸ”¥ ğŸ‘ 1 1 + Reply hengloose 11 days ago Amazing Reply MatthewFrank 11 days ago This is such an important initiative for transparency in model evaluation! Building trustworthy evaluation infrastructure requires careful architectural design. For anyone building evaluation systems or ML infrastructure, clear documentation is critical. I've been using InfraSketch ( https://www.infrasketch.net/ ) to document our evaluation pipelinesâ€”you describe the system architecture in plain English and get visual diagrams that you can iterate on conversationally. Makes it much easier to communicate how evaluation systems work and maintain documentation as they evolve. Reply harshakokel 9 days ago â€¢ edited 9 days ago This is a very important and timely initiative. Itâ€™s easy to get lost in the sea of leaderboards, each with its own format and reporting style. The Inspect AI log format brings muchâ€‘needed standardization, and having Hugging Face host evaluation logs is a real game changer. One reason many valuable benchmarks fade away is that original contributors often lack the resources to continuously maintain leaderboards. The Community Evals initiative has tremendous potential to address this gap, and I truly appreciate the effort behind it. Weâ€™re hoping to include our planning benchmark, ACPBench , as part of this ecosystemâ€”it's fully compatible with Inspect AI, the evaluation scripts are available on our GitHub. References ACPBench: Reasoning About Action, Change, and Planning, Harsha Kokel, Michael Katz, Kavitha Srinivas, Shirin Sohrabi , AAAI 2025 ACPBench Hard: Unrestrained Reasoning about Action, Change, and Planning, Harsha Kokel, Michael Katz, Kavitha Srinivas, Shirin Sohrabi , ICLR 2026 â• 1 1 + Reply Edit Preview Upload images, audio, and videos by dragging in the text input, pasting, or clicking here . Tap or paste here to upload images Comment Â· Sign up or log in to comment Upvote 72 +60 System theme Company TOS Privacy About Careers Website Models Datasets Spaces Pricing Docs import("\/front\/build\/kube-8f23bef\/index.js"); window.moonSha = "kube-8f23bef\/"; window.__hf_deferred = {}; if (["hf.co", "huggingface.co"].includes(window.location.hostname)) { const script = document.createElement("script"); script.src = "https://js.stripe.com/v3/"; script.async = true; document.head.appendChild(script); }

## å…³é”®è§‚ç‚¹

- æ ¸å¿ƒä¸»é¢˜æ¶‰åŠCommunityå’ŒEvals:
- ç ”ç©¶æ¥æº: Hugging Face Blog
- å†…å®¹è´¨é‡è¯„åˆ†: 0.95

## æ·±åº¦æ€è€ƒ

- è¿™é¡¹ç ”ç©¶çš„æ ¸å¿ƒå‡è®¾æ˜¯ä»€ä¹ˆï¼Ÿå®ƒä»¬æ˜¯å¦åˆç†ï¼Ÿ
- æ–¹æ³•çš„ä¸»è¦å±€é™æ€§æ˜¯ä»€ä¹ˆï¼Ÿæœªæ¥å¦‚ä½•æ”¹è¿›ï¼Ÿ
- è¿™ä¸ªå‘ç°å¯¹å®é™…åº”ç”¨åœºæ™¯æœ‰ä»€ä¹ˆå¯ç¤ºï¼Ÿ
- å¦‚æœæ¢ä¸€ä¸ªæ•°æ®é›†æˆ–ç¯å¢ƒï¼Œç»“æœæ˜¯å¦ä¾ç„¶æˆç«‹ï¼Ÿ
- è¿™é¡¹å·¥ä½œçš„åˆ›æ–°ç‚¹æ˜¯å¦è¢«å……åˆ†è®ºè¯ï¼Ÿ

## ç›¸å…³é“¾æ¥

- [[001-zettelkasten-æ˜¯ä»€ä¹ˆ]]
- [[009-å†™ä½œå°±æ˜¯æ€è€ƒ]]
- [[011-ä»ç¬”è®°åˆ°æ–‡ç« ]]


*RSS è‡ªåŠ¨é‡‡é›†æ°¸ä¹…åŒ– - å¤„ç†æ—¶é—´: 2026-02-21*
