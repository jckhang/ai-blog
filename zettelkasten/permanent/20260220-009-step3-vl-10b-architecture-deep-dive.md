---
id: 20260220-009-step3-vl-10b-architecture-deep-dive
title: STEP3-VL-10BæŠ€æœ¯æ¶æ„æ·±åº¦è§£æ
created: 2026-02-20
tags: ["stepfun", "multimodal", "vision-language", "rl", "architecture", "mobile-ai"]
source: "STEP3-VL-10B Technical Report (arXiv:2601.09668)"
source_url: "https://arxiv.org/abs/2601.09668"
content_length: 3200
quality_score: 0.92
related_notes: ["20260220-008-llm-research-trends-2026", "20260220-002-llm-powered-autonomous-agents", "20260220-005-reward-hacking-in-reinforcement-learning"]
---

# STEP3-VL-10B æŠ€æœ¯æ¶æ„æ·±åº¦è§£æ

> **æ ¸å¿ƒå¥‡è¿¹**: 10Bå‚æ•°æ¨¡å‹é€šè¿‡æ¶æ„åˆ›æ–° + 1,400+è½®RLï¼Œæ€§èƒ½åª²ç¾100B+æ¨¡å‹  
> **æ„ä¹‰**: éªŒè¯å°æ¨¡å‹ + heavy post-training = frontieræ€§èƒ½çš„å¯è¡Œæ€§  
> **åº”ç”¨**: å¤šæ¨¡æ€Agentã€æ‰‹æœºç«¯AIã€GUIè‡ªåŠ¨åŒ–

---

## ğŸ—ï¸ æ ¸å¿ƒæ¶æ„ï¼ˆä¸‰å¤§ç»„ä»¶ï¼‰

### 1. Perception Encoder (PE-lang)

**è§„æ ¼**: 1.8Bå‚æ•°ï¼Œè¯­è¨€ä¼˜åŒ–çš„è§†è§‰ç¼–ç å™¨

**è®¾è®¡åŸç†**: 
- é€‰ç”¨ **language-optimized** è€Œé spatial-optimized ç‰ˆæœ¬
- é¢„å¯¹é½çš„linguisticç‰¹å¾ â†’ æ›´å¥½çš„å¤šæ¨¡æ€èåˆ
- æ¥æº: Bolya et al. (2025)

**ä½œç”¨**: å°†è§†è§‰è¾“å…¥è½¬æ¢ä¸ºè¯­è¨€æ¨¡å‹å¯ç†è§£çš„token

---

### 2. Decoder: Qwen3-8B

**é€‰æ‹©ç†ç”±**:
- å¼ºå¤§çš„æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›
- å¯¹è§†è§‰-è¯­è¨€ä»»åŠ¡é€‚åº”æ€§å¼º
- å·²è¯æ˜åœ¨8Bè§„æ¨¡ä¸Šçš„æœ‰æ•ˆæ€§

**è¿æ¥æ–¹å¼**: ä¸PE-langé€šè¿‡projectoræ¡¥æ¥

---

### 3. Projector (ç©ºé—´ä¸‹é‡‡æ ·)

**å…³é”®è®¾è®¡**: ä¸¤ä¸ªè¿ç»­çš„stride-2å±‚

**æ•ˆæœ**:
- ç©ºé—´ç»´åº¦å‹ç¼© **16Ã—**
- ä¿ç•™å…³é”®ä¿¡æ¯çš„åŒæ—¶å¤§å¹…å‡å°‘tokenæ•°é‡
- ç±»ä¼¼Step-3å’ŒDeepSeek-OCRçš„è®¾è®¡

**æ„ä¹‰**: å‡å°‘è®¡ç®—å¼€é”€ï¼Œä½¿10Bæ¨¡å‹å¯å®ç”¨åŒ–

---

## ğŸ–¼ï¸ å›¾åƒå¤„ç†ç­–ç•¥

**Multi-cropç­–ç•¥**:
- **å…¨å±€è§†å›¾**: 728Ã—728
- **å±€éƒ¨è§†å›¾**: å¤šä¸ª 504Ã—504  crops

**ç›®çš„**:
- æ•è·å…¨å±€åœºæ™¯
- æå–ç»†èŠ‚åŒºåŸŸ
- å¹³è¡¡è®¡ç®—æ•ˆç‡ä¸ç²¾åº¦

---

## ğŸ“ ä½ç½®ç¼–ç 

**æ ‡å‡†1D RoPE** (Rotary Position Embedding)

- ç®€å•æœ‰æ•ˆ
- æ”¯æŒé•¿åºåˆ—ï¼ˆPaCoReä½¿ç”¨128K contextï¼‰

---

## ğŸ“ è®­ç»ƒé˜¶æ®µè¯¦è§£

### é˜¶æ®µ1: Unified Pre-training (å®Œå…¨è§£å†»)

**æ•°æ®**: 1.2T multimodal tokens (è·¨7ä¸ªé¢†åŸŸ)

**ç­–ç•¥**: Single-stage, fully unfrozen

**å…³é”®**: åŒæ—¶è®­ç»ƒè§†è§‰ç¼–ç å™¨å’Œè¯­è¨€è§£ç å™¨ï¼Œå»ºç«‹å†…åœ¨ååŒ

**ä¼˜åŒ–å™¨**: AdamW

**æ€»è¿­ä»£**: 370Kæ¬¡

---

#### Sub-phase A: æ–‡æœ¬ä¸»å¯¼æ¨ç† (å‰900B tokens)

- **æ–‡æœ¬:å¤šæ¨¡æ€æ¯”**: 9:1
- **ç›®æ ‡**: å­¦ä¹ é€šç”¨çŸ¥è¯†ã€æ•™è‚²ä»»åŠ¡
- **å­¦ä¹ ç‡**: \(1 \times 10^{-5}\) å¼€å§‹

---

#### Sub-phase B: å¹³è¡¡å¤šæ¨¡æ€èåˆ (å300B tokens)

- **æ–‡æœ¬:å¤šæ¨¡æ€æ¯”**: 1:1
- **ç›®æ ‡**: è§†è§‰-è¯­è¨€æ·±åº¦èåˆ
- **å­¦ä¹ ç‡è¡°å‡**: \(1 \times 10^{-5} â†’ 6 \times 10^{-6}\)

---

### é˜¶æ®µ2: Supervised Finetuning (SFT) ä¸¤é˜¶æ®µ

**æ€»æ•°æ®**: ~226B tokens

---

#### SFT Stage 1: æ–‡æœ¬ä¸»å¯¼ (~190B tokens)

- Ratio: 9:1 (text:multimodal)
- å»ºç«‹åŸºç¡€æŒ‡ä»¤è·Ÿéšèƒ½åŠ›

---

#### SFT Stage 2: å¹³è¡¡ (~36B tokens)

- Ratio: 1:1
- å¼ºåŒ–å¤šæ¨¡æ€ä»»åŠ¡æ€§èƒ½

---

### é˜¶æ®µ3: Reinforcement Learning (RL) - æ ¸å¿ƒç§˜å¯†æ­¦å™¨

**æ€»è¿­ä»£**: **>1,400æ¬¡** (è¿œè¶…é€šå¸¸çš„100-200æ¬¡)

**ä¸¤å¤§RLåˆ†æ”¯**:

#### 3.1 RLVR (Reinforcement Learning with Verifiable Rewards)

- **è¿­ä»£**: 600æ¬¡
- **ä»»åŠ¡ç±»å‹**: 
  - æ•°å­¦é—®é¢˜ï¼ˆå¯éªŒè¯ç­”æ¡ˆï¼‰
  - å‡ ä½•æ¨ç†
  - ç‰©ç†é—®é¢˜
  - æ„ŸçŸ¥ä»»åŠ¡
  - GUI grounding
- **ç‰¹ç‚¹**: å¥–åŠ±ä¿¡å·ç²¾ç¡®ï¼Œæ— éœ€äººç±»æ ‡æ³¨

---

#### 3.2 RLHF (Reinforcement Learning from Human Feedback)

- **è¿­ä»£**: 300æ¬¡
- **ä»»åŠ¡**: å¼€æ”¾å¼ç”Ÿæˆï¼ˆå¯¹è¯è´¨é‡ã€å®‰å…¨æ€§ï¼‰
- **ç‰¹ç‚¹**: æå‡å¯¹é½åº¦å’Œhuman preference

---

#### 3.3 PaCoRe Training (Parallel Coordinated Reasoning)

- **è¿­ä»£**: 500æ¬¡
- **ç›®æ ‡**: æ‰©å±•æµ‹è¯•æ—¶è®¡ç®—ï¼ˆtest-time computeï¼‰
- **æ–¹æ³•**: å¹¶è¡Œæ¢ç´¢16ä¸ªè§†è§‰å‡è®¾ï¼Œèšåˆæœ€ç»ˆç­”æ¡ˆ
- **Contexté•¿åº¦**: æœ€å¤§128K tokens
- **æ¨¡å¼**: é«˜çº§æ¨ç†æ¨¡å¼ï¼Œéé»˜è®¤

---

## ğŸ”„ RLè®­ç»ƒå…¬å¼ï¼ˆæŠ€æœ¯ç»†èŠ‚ï¼‰

**PPOç›®æ ‡å‡½æ•°** (æ¦‚ç‡æ¯”):

\[
\rho_t(\theta) = \frac{\pi_\theta(a_t|s_t)}{\pi_{\text{old}}(a_t|s_t)}
\]

**ä¼˜åŠ¿ä¼°è®¡** (GAE):

\[
\hat{A}_t = \sum_{l=0}^{T-t-1} (\gamma \lambda)^l \delta_{t+l}
\]

**where**:
- \(\pi_\theta\): å½“å‰ç­–ç•¥
- \(\pi_{\text{old}}\): æ—§ç­–ç•¥
- \(\gamma\): æŠ˜æ‰£å› å­
- \(\lambda\): GAEå‚æ•°
- \(\delta_{t+l}\): TD-error

---

## ğŸš€ æ¨ç†æ¨¡å¼

### Mode 1: SeRe (Sequential Reasoning)

- æ ‡å‡†Chain-of-Thought
- æœ€å¤§é•¿åº¦: 64K tokens
- **é»˜è®¤æ¨¡å¼**ï¼ˆé™¤éç‰¹åˆ«è¯´æ˜ï¼‰

---

### Mode 2: PaCoRe (Parallel Coordinated Reasoning)

**æ ¸å¿ƒæ€æƒ³**: åˆ†é…æµ‹è¯•æ—¶è®¡ç®—åˆ°å¹¶è¡Œè§†è§‰æ¢ç´¢

**æµç¨‹**:
1. ç”Ÿæˆ16ä¸ªå¹¶è¡Œrolloutsï¼ˆå¹¶è¡Œæ¢ç´¢ï¼‰
2. èšåˆè¯æ®
3. åˆæˆæœ€ç»ˆç­”æ¡ˆ

**æ•ˆæœ**: æ€§èƒ½æå‡ï¼ˆå°¤å…¶æ•°å­¦æ¨ç†ï¼‰

**é…ç½®**:
- Contexté•¿åº¦: 128K max
- å¹¶è¡Œåº¦: 16
- å¼€é”€: 16Ã—è®¡ç®—æˆæœ¬

---

## ğŸ“Š æ€§èƒ½åŸºå‡†ï¼ˆ2026å¹´1æœˆæ•°æ®ï¼‰

### å¯¹æ¯”100B+å¤§æ¨¡å‹

| Benchmark | STEP3-VL-10B | GLM-4.6V-106B | Qwen3-VL-235B |
|-----------|--------------|---------------|---------------|
| **MMMU** | 80.11% (PaCoRe) | 75.20% | 78.70% |
| **MMBench** | 92.38% | 92.75% | 92.70% |
| **AIME 2025** | 94.43% | 71.88% | 83.59% |
| **MathVision** | 75.95% | 63.50% | 72.10% |
| **OCRBench** | 89.00% | 86.20% | 87.30% |
| **ScreenSpot-V2** | 92.61% | - | - |

**ç»“è®º**: 10Bæ¨¡å‹å…¨é¢è¶…è¶Šæˆ–åŒ¹æ•Œ10-20å€å‚æ•°æ¨¡å‹ âœ…

---

### å¯¹æ¯”7B-10Bå¼€æºæ¨¡å‹

| èƒ½åŠ›é¢†åŸŸ | åŸºå‡† | STEP3-VL-10B | æœ€ä½³ç«å“ | ä¼˜åŠ¿ |
|---------|------|--------------|----------|------|
| **STEMæ¨ç†** | MMMU | 78.11% | ~73% | +5pp |
| **æ•°å­¦è§†è§‰** | MathVista | 83.97% | ~82% | +2pp |
| **GUI grounding** | ScreenSpot-V2 | 92.61% | 90.82% | SOTA âœ… |
| **ä»£ç ** | HumanEval-V | 66.05% | 31.96% | +34pp â­ |
| **ç©ºé—´ç†è§£** | BLINK | 66.79% | ~62% | +5pp |

---

## ğŸ’¡ å…³é”®æŠ€æœ¯æ´å¯Ÿ

### 1. Unfrozen Pre-training çš„é‡è¦æ€§

**ä¼ ç»Ÿåšæ³•**: å†»ç»“è§†è§‰ç¼–ç å™¨ï¼Œåªå¾®è°ƒdecoder

**STEP3åšæ³•**: å®Œå…¨è§£å†»ï¼Œè”åˆä¼˜åŒ–

**ä¼˜åŠ¿**:
- è§†è§‰-è¯­è¨€ç‰¹å¾æ·±åº¦èåˆ
- æ›´é«˜æ¨¡æ€å¯¹é½åº¦
- æ€§èƒ½æå‡æ˜¾è‘—

**ä»£ä»·**:
- è®­ç»ƒæ—¶é—´å»¶é•¿
- éœ€è¦æ›´å¤šGPUèµ„æº

---

### 2. Post-training Scaling > Parameter Scaling

**æ ¸å¿ƒå‘ç°**: 1,400è½®RLä½¿10Bæ¨¡å‹è¾¾åˆ°100B+æ€§èƒ½

**å¯ç¤º**:
- ä¸ç›²ç›®è¿½æ±‚å‚æ•°è§„æ¨¡
- æŠ•èµ„post-trainingï¼ˆSFT + RLï¼‰
- é«˜è´¨é‡æ•°æ® + å¤§è§„æ¨¡RL = é«˜æ•ˆæ¨¡å‹

---

### 3. RLVRçš„å¯éªŒè¯å¥–åŠ±

**æ•°å­¦/å‡ ä½•ä»»åŠ¡**: ç­”æ¡ˆå”¯ä¸€ï¼Œè‡ªåŠ¨éªŒè¯

**GUI grounding**: æ¯ä¸€æ­¥æ“ä½œå¯éªŒè¯ï¼ˆç‚¹å‡»æ­£ç¡®åŒºåŸŸï¼‰

**ä¼˜åŠ¿**: æ— éœ€äººç±»æ ‡æ³¨ï¼Œå¯è§„æ¨¡åŒ–ä¸Šåƒè½®

---

### 4. PaCoReçš„æµ‹è¯•æ—¶è®¡ç®—

**ç†å¿µ**: æ¨ç†æ—¶åˆ†é…æ›´å¤šè®¡ç®—ï¼Œè€Œéè®­ç»ƒæ—¶

**æ–¹æ³•**: å¹¶è¡Œæ¢ç´¢ + è¯æ®èšåˆ

**åº”ç”¨åœºæ™¯**:
- å¤æ‚æ•°å­¦é¢˜ï¼ˆéœ€è¦å¤šè§’åº¦æ€è€ƒï¼‰
- è§†è§‰æ¨ç†ï¼ˆå¤šä¸ªå‡è®¾éªŒè¯ï¼‰
- GUIä»»åŠ¡ï¼ˆæ¢ç´¢ä¸åŒæ“ä½œè·¯å¾„ï¼‰

---

## ğŸ¯ å¯¹Eè€å¸ˆé¡¹ç›®çš„ç›´æ¥å¯ç¤º

### 1. å¤šæ¨¡æ€Agentæ¶æ„å‚è€ƒ

**æ¨èæ¶æ„** (ä»¿STEP3):

```
PE-lang (1.8Bè§†è§‰ç¼–ç å™¨)  â† æ‰‹æœºå¤šå¸§/å±å¹•æˆªå›¾
        â†“ (Projector, stride-2Ã—2=16Ã—ä¸‹é‡‡æ ·)
Qwen3-8B (è¯­è¨€è§£ç å™¨)     â† ç”ŸæˆåŠ¨ä½œã€æŒ‡ä»¤
        â†“
RLè®­ç»ƒ (600+ iterations) â† ä½¿ç”¨å¯éªŒè¯å¥–åŠ±ï¼ˆactionæ­£ç¡®æ€§ï¼‰
```

**å…³é”®å‚æ•°**:
- è§†è§‰ç¼–ç å™¨: 1-2Bå‚æ•°
- è¯­è¨€æ¨¡å‹: 8-10Bå‚æ•°
- Projector: 2å±‚stride-2
- RL: >600è½®ï¼ˆåˆ†é˜¶æ®µï¼‰

---

### 2. ç§»åŠ¨ç«¯éƒ¨ç½²å¯è¡Œæ€§

**æ€»å‚æ•°**: 10B â†’ 4-bité‡åŒ–å ~5GBå†…å­˜

**æ¨ç†ä¼˜åŒ–**:
- KV cacheä¼˜åŒ–ï¼ˆ128K contextæ—¶ä»å¯ç®¡ç†ï¼‰
- Projectoré«˜æ•ˆä¸‹é‡‡æ ·
- PaCoReæ¨¡å¼ä¸‹éœ€è¦16Ã—å¹¶è¡Œï¼ˆæ‰‹æœºå¯èƒ½ä¸è¶³ï¼‰

**å»ºè®®**: 
- åŸºç¡€æ‰‹æœºéƒ¨ç½²SeReæ¨¡å¼ï¼ˆ64K contextï¼‰
- å¤æ‚ä»»åŠ¡ä½¿ç”¨Server-side PaCoReï¼ˆcloud fallbackï¼‰

---

### 3. RLè®­ç»ƒç­–ç•¥

**å€Ÿé‰´STEP3**:

1. **SFTé˜¶æ®µ1** (9:1 ratio): 190B tokens, å»ºç«‹åŸºç¡€èƒ½åŠ›
2. **SFTé˜¶æ®µ2** (1:1 ratio): 36B tokens, å¼ºåŒ–å¤šæ¨¡æ€
3. **RLVR** (600è½®): å¯éªŒè¯ä»»åŠ¡ï¼ˆæ•°å­¦ã€GUIæ“ä½œï¼‰
4. **RLHF** (300è½®): äººç±»åå¥½ï¼ˆå¯¹è¯è´¨é‡ï¼‰
5. **PaCoRe** (500è½®): é«˜çº§æ¨ç†æ¨¡å¼

**æ€»è®¡**: 1,400è½®post-training

**æˆæœ¬**:
- å‡è®¾æ¯è½®1000æ¡è½¨è¿¹
- æ€»æ•°æ®é‡: 1.4Mæ¡äº¤äº’
- éœ€è¦è‡ªåŠ¨åŒ–æ”¶é›†å’Œè¯„ä¼°ç³»ç»Ÿ

---

### 4. GUI Agentä»»åŠ¡çš„éªŒè¯å¥–åŠ±è®¾è®¡

**å‚è€ƒSTEP3çš„ScreenSpot-V2** (92.61%å‡†ç¡®ç‡)

**å¥–åŠ±è®¾è®¡**:

- **æ­£ç¡®ç‚¹å‡»ç›®æ ‡åŒºåŸŸ**: +1.0
- **ç‚¹å‡»é™„è¿‘** (IoU>0.5): +0.5
- **ç‚¹å‡»é”™è¯¯**: -1.0
- **ä»»åŠ¡å®Œæˆ**: +2.0 (é¢å¤–å¥–åŠ±)
- **è¿‡æ—©ç»ˆæ­¢**: -0.5

**éªŒè¯æ–¹å¼**: è‡ªåŠ¨ç”ŸæˆGUIå…ƒç´ çš„ground truthåæ ‡

---

## ğŸ”¬ å®éªŒå¤ç°å»ºè®®

### ç¬¬ä¸€æ­¥: è·å–æ¨¡å‹

**Hugging Face**: `stepfun-ai/Step3-VL-10B`
**ModelScope**: å›½å†…é•œåƒ

---

### ç¬¬äºŒæ­¥: ç†è§£æ¶æ„

**é˜…è¯»æœ¬ç¬”è®°**ï¼ˆå·²å®Œæˆï¼‰
**é˜…è¯»åŸè®ºæ–‡**: arXiv:2601.09668 (50é¡µ)

---

### ç¬¬ä¸‰æ­¥: åŸºå‡†æµ‹è¯•

**ä½¿ç”¨ScreenSpot-V2**:

```python
from transformers import AutoProcessor, AutoModelForCausalLM
# åŠ è½½æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained("stepfun-ai/Step3-VL-10B", trust_remote_code=True)
processor = AutoProcessor.from_pretrained("stepfun-ai/Step3-VL-10B", trust_remote_code=True)

# æµ‹è¯•GUI grounding
image = load_screenshot()
text = "ç‚¹å‡»'æäº¤'æŒ‰é’®"
inputs = processor(messages=[{"role": "user", "content": [{"type": "image", "url": image}, {"type": "text", "text": text}]}], return_tensors="pt")
output = model.generate(**inputs)
```

**è¯„ä¼°**: å¯¹æ¯”åŸºçº¿ï¼ˆå¦‚Qwen3-VL-8Bï¼‰

---

### ç¬¬å››æ­¥: RLå®éªŒè®¾è®¡

**ç›®æ ‡**: åœ¨æ‰‹æœºAgentä»»åŠ¡ä¸Šè¾¾åˆ°ç±»ä¼¼ScreenSpot-V2çš„æ€§èƒ½

**æ•°æ®é›†**: æ”¶é›†1000+æ‰‹æœºç•Œé¢ + æ­£ç¡®æ“ä½œè½¨è¿¹

**RLæ¡†æ¶**:
- ä½¿ç”¨PPOï¼ˆå‚è€ƒSTEP3å…¬å¼ï¼‰
- å¯éªŒè¯å¥–åŠ±è®¾è®¡ï¼ˆç‚¹å‡»å‡†ç¡®æ€§ï¼‰
- è®­ç»ƒ600è½®ï¼ˆè‡³å°‘ï¼‰

**è¯„ä¼°æŒ‡æ ‡**:
- GUI groundingå‡†ç¡®ç‡
- ä»»åŠ¡å®Œæˆç‡
- æ­¥éª¤æ•ˆç‡ï¼ˆæ­¥éª¤æ•°/ä»»åŠ¡ï¼‰

---

## âš ï¸ æ½œåœ¨é£é™©ä¸æŒ‘æˆ˜

### 1. è®­ç»ƒæˆæœ¬

**ä¼°ç®—**:
- 1.2T tokens pre-training: å·¨å¤§æˆæœ¬ï¼ˆå¤šå¡æ•°æœˆï¼‰
- RL 1,400è½®: éœ€è¦æ¨¡æ‹Ÿç¯å¢ƒå’Œæ”¶é›†ç³»ç»Ÿ

**å»ºè®®**: åŸºäºBaseæ¨¡å‹å¼€å§‹ï¼Œé¿å…ä»å¤´pre-train

---

### 2. æ•°æ®è´¨é‡

**PE-langæ•ˆæœ**ä¾èµ–è¯­è¨€å¯¹é½è´¨é‡

**å»ºè®®**: ä½¿ç”¨StepFunå·²å‘å¸ƒçš„é¢„è®­ç»ƒç¼–ç å™¨ï¼ˆreproduceï¼‰

---

### 3. PaCoReçš„è®¡ç®—å¼€é”€

16Ã—å¹¶è¡Œæ¨ç† â†’ éœ€é«˜æ€§èƒ½GPUé›†ç¾¤

**æ›¿ä»£**: åˆæœŸä½¿ç”¨SeReæ¨¡å¼ï¼ŒåæœŸå†ä¼˜åŒ–PaCoRe

---

### 4. ç§»åŠ¨ç«¯éƒ¨ç½²é™åˆ¶

- 10Bæ¨¡å‹ + 4-bité‡åŒ– â†’ ~5GBå†…å­˜
- 128K context â†’ KV cache ~2GB
- é«˜ç«¯Androidæ‰‹æœºå‹‰å¼ºå¯ç”¨

**æ–¹æ¡ˆ**: 
- éƒ¨åˆ†è®¡ç®—offloadåˆ°cloud
- æ··åˆæ¨ç†ï¼ˆæœ¬åœ°å°æ¨¡å‹ + äº‘ç«¯å¤§æ¨¡å‹ï¼‰

---

## ğŸ”­ æœªæ¥æ–¹å‘

1. **æ›´å°æ¨¡å‹**: å°è¯•3Bå‚æ•°ç‰ˆæœ¬ï¼ˆå¦‚æœä¿æŒæ€§èƒ½ï¼‰
2. **æ›´å°‘RLè½®æ¬¡**: æ¢ç´¢RLæ•ˆç‡ï¼ˆSTEP3ç”¨äº†1,400è½®ï¼Œèƒ½å¦å‡å°‘ï¼Ÿï¼‰
3. **Domain-specific**: é’ˆå¯¹æ‰‹æœºåœºæ™¯å®šåˆ¶SFTæ•°æ®é›†
4. **Lightweight PaCoRe**: æ‰‹æœºç«¯2-4 parallel paths
5. **é‡åŒ–åRL**: æ˜¯å¦èƒ½åœ¨INT4æ¨¡å‹ä¸Šç»§ç»­RLè®­ç»ƒï¼Ÿ

---

## ğŸ“š æ ¸å¿ƒå¼•ç”¨

- **arXiv**: 2601.09668 (50é¡µæŠ€æœ¯æŠ¥å‘Š)
- **GitHub**: https://github.com/stepfun-ai/Step3-VL-10B
- **Hugging Face**: stepfun-ai/Step3-VL-10B
- **æ€§èƒ½å¯¹æ¯”è§†é¢‘**: https://www.youtube.com/watch?v=FAkub8tr2ZI

---

**æ€»ç»“**: STEP3-VL-10Bæ˜¯**å°æ¨¡å‹+heavy post-training**çš„é‡Œç¨‹ç¢‘ã€‚å®ƒè¯æ˜ï¼š**å‚æ•°é‡ä¸æ˜¯ä¸€åˆ‡ï¼Œè®­ç»ƒåè®¡ç®—æ‰æ˜¯å…³é”®**ã€‚å¯¹äºæ™ºè·ƒåƒé‡Œçš„å¤šæ¨¡æ€Agenté¡¹ç›®ï¼Œè¿™æ˜¯å®Œç¾çš„æ¶æ„è“å›¾ã€‚ğŸš€

---

*Created: 2026-02-20 12:30 | Quality: 0.92 | TODO: learning-new-id*
