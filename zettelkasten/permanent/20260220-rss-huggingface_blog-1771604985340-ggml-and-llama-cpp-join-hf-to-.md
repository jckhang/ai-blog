---
id: 20260220-rss-huggingface_blog-001-ggml-and-llama-cpp-join-hf-to-ensure-the-long-term
title: GGML and llama.cpp join HF to ensure the long-term progress of Local AI
created: 2026-02-21
tags: ["rss","ai_research","auto-import","permanent"]
source: "Hugging Face Blog"
source_url: "https://huggingface.co/blog/ggml-joins-hf"
source_type: "article"
content_length: 8579
quality_score: 0.95
---

# GGML and llama.cpp join HF to ensure the long-term progress of Local AI

## æ¥æºä¿¡æ¯

- **æ¥æº**: Hugging Face Blog
- **å‘å¸ƒæ—¶é—´**: è§åŸæ–‡
- **åŸæ–‡é“¾æ¥**: https://huggingface.co/blog/ggml-joins-hf
- **é‡‡é›†æ—¶é—´**: 2026-02-21

## æ ¸å¿ƒå†…å®¹

const guestTheme = document.cookie.match(/theme=(\w+)/)?.[1]; document.documentElement.classList.toggle('dark', guestTheme === 'dark' || ( (!guestTheme || guestTheme === 'system') && window.matchMedia('(prefers-color-scheme: dark)').matches)); GGML and llama.cpp join HF to ensure the long-term progress of Local AI ((window.plausible = window.plausible || function () { (plausible.q = plausible.q || []).push(arguments); }), (plausible.init = plausible.init || function (i) { plausible.o = i || {}; })); plausible.init({ customProperties: { loggedIn: "false", }, endpoint: "/api/event", }); window.hubConfig = {"features":{"signupDisabled":false},"sshGitUrl":"git@hf.co","moonHttpUrl":"https:\/\/huggingface.co","captchaApiKey":"bd5f2066-93dc-4bdd-a64b-a24646ca3859","datasetViewerPublicUrl":"https:\/\/datasets-server.huggingface.co","stripePublicKey":"pk_live_x2tdjFXBCvXo2FFmMybezpeM00J6gPCAAc","environment":"production","userAgent":"HuggingFace (production)","spacesIframeDomain":"hf.space","spacesApiUrl":"https:\/\/api.hf.space","docSearchKey":"ece5e02e57300e17d152c08056145326e90c4bff3dd07d7d1ae40cf1c8d39cb6","logoDev":{"apiUrl":"https:\/\/img.logo.dev\/","apiKey":"pk_UHS2HZOeRnaSOdDp7jbd5w"}}; window.requestId = "Root=1-69988bf8-4cee973d0e9a3bc5037eaca8"; window.featureFlags = {"buckets":false}; Hugging Face Models Datasets Spaces Community Docs Enterprise Pricing Log In Sign Up Back to Articles GGML and llama.cpp join HF to ensure the long-term progress of Local AI Published February 20, 2026 Update on GitHub Upvote 77 +71 Georgi Gerganov ggerganov Follow Xuan-Son Nguyen ngxson Follow Aleksander Grygier allozaur Follow Lysandre lysandre Follow Victor Mustar victor Follow Julien Chaumond julien-c Follow What will change for llama.cpp, the open source project and the community? Technical focus Our long term vision We are super happy to announce that GGML, creators of Llama.cpp, are joining HF in order to keep future AI open. ğŸ”¥ Georgi Gerganov and team are joining HF with the goal of scaling and supporting the community behind ggml and llama.cpp as Local AI continues to make exponential progress in the coming years. We've been working with Georgi and team for quite some time (we even have awesome core contributors to llama.cpp like Son and Alek in the team already) so this has been a very natural process. llama.cpp is the fundamental building block for local inference, and transformers is the fundamental building block for model definition, so this is basically a match made in heaven. â¤ï¸ What will change for llama.cpp, the open source project and the community? Not much â€“ Georgi and team still dedicate 100% of their time maintaining llama.cpp and have full autonomy and leadership on the technical directions and the community.
HF is providing the project with long-term sustainable resources, improving the chances of the project to grow and thrive. The project will continue to be 100% open-source and community driven as it is now. Technical focus llama.cpp is the fundamental building block for local inference, and transformers is the fundamental building block for definition of models and architectures, so weâ€™ll work on making sure itâ€™s as seamless as possible in the future (almost â€œsingle-clickâ€) to ship new models in llama.cpp from the transformers library â€˜source of truthâ€™ for model definitions. Additionally, we will improve packaging and user experience of ggml-based software. As we enter the phase in which local inference becomes a meaningful and competitive alternative to cloud inference, it is crucial to improve and simplify the way in which casual users deploy and access local models. We will work towards making llama.cpp ubiquitous and readily available everywhere. Our long term vision Our shared goal is to provide the community with the building blocks to make open-source superintelligence accessible to the world over the coming years. We will achieve this together with the growing Local AI community, as we continue to build the ultimate inference stack that runs as efficiently as possible on our devices. More Articles from our Blog llm fine-tuning open-source Codex is Open Sourcing AI models 72 December 11, 2025 llm fine-tuning open-source Hot We Got Claude to Fine-Tune an Open Source LLM 596 December 4, 2025 Community Big congrats to GGML and Hugging Face! Great news for the Local AI community. Excited to see llama.cpp grow stronger and make local AI easier for everyone! \n&quot;,&quot;updatedAt&quot;:&quot;2026-02-20T15:41:15.501Z&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;648ea764baf3573e020693a1&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/648ea764baf3573e020693a1/5hX2g9NwZG-R98_FNWMOx.jpeg&quot;,&quot;fullname&quot;:&quot;Trainee.Luo&quot;,&quot;name&quot;:&quot;Bright8192&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;isUserFollowing&quot;:false}},&quot;numEdits&quot;:0,&quot;identifiedLanguage&quot;:{&quot;language&quot;:&quot;en&quot;,&quot;probability&quot;:0.8431777954101562},&quot;editors&quot;:[&quot;Bright8192&quot;],&quot;editorAvatarUrls&quot;:[&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/648ea764baf3573e020693a1/5hX2g9NwZG-R98_FNWMOx.jpeg&quot;],&quot;reactions&quot;:[],&quot;isReport&quot;:false}},{&quot;id&quot;:&quot;69988a512ccc26f7b657ae8a&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;674913cd0fc71e443a1136f0&quot;,&quot;avatarUrl&quot;:&quot;/avatars/e599f3e10398c78394a5df93dfb2c72e.svg&quot;,&quot;fullname&quot;:&quot;Armir&quot;,&quot;name&quot;:&quot;Room64&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;isUserFollowing&quot;:false},&quot;createdAt&quot;:&quot;2026-02-20T16:22:41.000Z&quot;,&quot;type&quot;:&quot;comment&quot;,&quot;data&quot;:{&quot;edited&quot;:false,&quot;hidden&quot;:false,&quot;latest&quot;:{&quot;raw&quot;:&quot;LLama.cpp is the best AI project by far, super reactive to bug solve, very competent team, love you guys, you desserve it&quot;,&quot;html&quot;:&quot; LLama.cpp is the best AI project by far, super reactive to bug solve, very competent team, love you guys, you desserve it \n&quot;,&quot;updatedAt&quot;:&quot;2026-02-20T16:22:41.151Z&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;674913cd0fc71e443a1136f0&quot;,&quot;avatarUrl&quot;:&quot;/avatars/e599f3e10398c78394a5df93dfb2c72e.svg&quot;,&quot;fullname&quot;:&quot;Armir&quot;,&quot;name&quot;:&quot;Room64&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;isUserFollowing&quot;:false}},&quot;numEdits&quot;:0,&quot;identifiedLanguage&quot;:{&quot;language&quot;:&quot;en&quot;,&quot;probability&quot;:0.9301363825798035},&quot;editors&quot;:[&quot;Room64&quot;],&quot;editorAvatarUrls&quot;:[&quot;/avatars/e599f3e10398c78394a5df93dfb2c72e.svg&quot;],&quot;reactions&quot;:[],&quot;isReport&quot;:false}}],&quot;status&quot;:&quot;open&quot;,&quot;isReport&quot;:false,&quot;pinned&quot;:false,&quot;locked&quot;:false,&quot;collection&quot;:&quot;community_blogs&quot;},&quot;contextAuthors&quot;:[&quot;ggerganov&quot;,&quot;ngxson&quot;,&quot;allozaur&quot;,&quot;lysandre&quot;,&quot;victor&quot;,&quot;julien-c&quot;],&quot;primaryEmailConfirmed&quot;:false,&quot;discussionRole&quot;:0,&quot;acceptLanguages&quot;:[&quot;en&quot;],&quot;withThread&quot;:true,&quot;cardDisplay&quot;:false,&quot;repoDiscussionsLocked&quot;:false}"> Bright8192 about 1 hour ago Big congrats to GGML and Hugging Face! Great news for the Local AI community. Excited to see llama.cpp grow stronger and make local AI easier for everyone! Reply Room64 7 minutes ago LLama.cpp is the best AI project by far, super reactive to bug solve, very competent team, love you guys, you desserve it Reply Edit Preview Upload images, audio, and videos by dragging in the text input, pasting, or clicking here . Tap or paste here to upload images Comment Â· Sign up or log in to comment Upvote 77 +65 System theme Company TOS Privacy About Careers Website Models Datasets Spaces Pricing Docs import("\/front\/build\/kube-4450e18\/index.js"); window.moonSha = "kube-4450e18\/"; window.__hf_deferred = {}; if (["hf.co", "huggingface.co"].includes(window.location.hostname)) { const script = document.createElement("script"); script.src = "https://js.stripe.com/v3/"; script.async = true; document.head.appendChild(script); }

## å…³é”®è§‚ç‚¹

- ç ”ç©¶æ¥æº: Hugging Face Blog
- å†…å®¹è´¨é‡è¯„åˆ†: 0.95

## æ·±åº¦æ€è€ƒ

<!-- å¯¹ä¸Šè¿°è§‚ç‚¹çš„åæ€ã€è´¨ç–‘ã€å»¶ä¼¸é—®é¢˜ -->

## ç›¸å…³é“¾æ¥

- [[016-llm-research-automation]]
- [[017-æ·±åº¦ç ”ç©¶å·¥å…·é“¾]]
- [[018-ç ”ç©¶æ‰«æè‡ªåŠ¨åŒ–çš„ZKé›†æˆç­–ç•¥]]

---
*RSS è‡ªåŠ¨é‡‡é›†æ°¸ä¹…åŒ– - å¤„ç†æ—¶é—´: 2026-02-21*
