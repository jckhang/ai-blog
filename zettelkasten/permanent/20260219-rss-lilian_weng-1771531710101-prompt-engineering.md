---
id: 20260219-rss-lilian_weng-001-prompt-engineering
title: Prompt Engineering
created: 2026-02-21
tags: ["rss","engineering","auto-import","permanent"]
source: "Lilian Weng's Blog"
source_url: "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/"
source_type: "article"
content_length: 723
quality_score: 0.70
---

# Prompt Engineering

## 来源信息

- **来源**: Lilian Weng's Blog
- **发布时间**: 见原文
- **原文链接**: https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/
- **采集时间**: 2026-02-21

## 核心内容

**Prompt Engineering**, also known as **In-Context Prompting**, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes *without* updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.

This post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my [previous post](https://lilianweng.github.io/posts/2021-01-02-controllable-text-generation/) on controllable text generation.

## 关键观点

- 核心主题涉及Prompt和Engineering
- 研究来源: Lilian Weng's Blog
- 内容质量评分: 0.70

## 深度思考

<!-- 对上述观点的反思、质疑、延伸问题 -->

## 相关链接

- [[016-llm-research-automation]]
- [[017-深度研究工具链]]
- [[018-研究扫描自动化的ZK集成策略]]

---
*RSS 自动采集永久化 - 处理时间: 2026-02-21*
